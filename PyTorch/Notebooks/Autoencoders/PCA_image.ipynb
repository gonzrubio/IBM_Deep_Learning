{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product\" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> PCA for Large Datasets </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In this lab, you will calculate the covariance matrix for datasets with a large number of samples; then, you will use PCA to transform the datase</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1- Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download eigenvectors and eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-09 21:48:30--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/meet_up/12.02.2020/eigenvectors.pt\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 262493 (256K) [application/octet-stream]\n",
      "Saving to: ‘eigenvectors.pt’\n",
      "\n",
      "eigenvectors.pt     100%[===================>] 256.34K  1.26MB/s    in 0.2s    \n",
      "\n",
      "2020-10-09 21:48:31 (1.26 MB/s) - ‘eigenvectors.pt’ saved [262493/262493]\n",
      "\n",
      "--2020-10-09 21:48:31--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/meet_up/12.02.2020/eigenvalues.pt\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2393 (2.3K) [application/octet-stream]\n",
      "Saving to: ‘eigenvalues.pt’\n",
      "\n",
      "eigenvalues.pt      100%[===================>]   2.34K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-10-09 21:48:31 (5.25 MB/s) - ‘eigenvalues.pt’ saved [2393/2393]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/meet_up/12.02.2020/eigenvectors.pt\n",
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/meet_up/12.02.2020/eigenvalues.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==6.2.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "  Found existing installation: Pillow 7.2.0\n",
      "    Uninstalling Pillow-7.2.0:\n",
      "      Successfully uninstalled Pillow-7.2.0\n",
      "Successfully installed Pillow-6.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==6.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following function to visualize data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def show_data(data_sample,y,raw_image=True):\n",
    "    if raw_image:\n",
    "        plt.imshow(data_sample[0].numpy().reshape(16, 16), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(data_sample[0].numpy().reshape(16, 16))\n",
    "    plt.title('y = ' + str(y.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " PCA transform class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class transform(object):\n",
    "    def __init__(self, eigenvalues,eigenvectors):\n",
    "        self.eigenvalues=eigenvalues\n",
    "        self.eigenvectors=eigenvectors                \n",
    "        \n",
    "        #calculate the diagonal matrix of eigenvalues\n",
    "        self.diag=torch.eye(eigenvalues.shape[0])\n",
    "        for n,eigenvalue in enumerate(eigenvalues[:,0]):            \n",
    "            self.diag[n,n]=(eigenvalue+0.01)**(0.5)                    \n",
    "        \n",
    "        self.Qin=torch.inverse(diag)\n",
    "        \n",
    "    def PCA(self,X):        \n",
    "        return torch.mm(X[0].view(1,-1),self.eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The image is a rectangular  tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">2- Load Data</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=composed )\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "the image is a rectangler tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.32_image_values.png\" width=\"550\" alt=\"MNIST elements\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We can covert the tensor to a 1D tensor of vector and perform PCA or ZCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2image_to_vector.gif\" width=\"550\" alt=\"Flattern Image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "In this cell will calculate the Covariance Matrix and save it. We do it in a way that we don't need to store all the samples in memory. This takes some time so you can load the results in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "dim=train_dataset[0][0].shape[1]*train_dataset[0][0].shape[2]\n",
    "\n",
    "mean=torch.zeros((1,dim))\n",
    "C=torch.zeros((dim,dim))\n",
    "N_samples=len(train_dataset)\n",
    "for n in range(N_samples):\n",
    "    mean=mean+train_dataset[0][0].view(-1,1)\n",
    "    \n",
    "mean=mean/N_samples\n",
    "\n",
    "for n in range(N_samples):\n",
    "    x=train_dataset[0][0].view(1,-1)\n",
    "    x=x-mean\n",
    "    \n",
    "    C+=torch.mm(torch.t(x),x)\n",
    "    \n",
    "C=C/N_samples\n",
    "\n",
    "eigenvalues,eigenvectors=torch.eig(C,True)\n",
    "torch.save(eigenvalues, 'eigenvalues.pt') \n",
    "torch.save(eigenvectors, 'eigenvectors.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Load eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "eigenvalues = torch.load('eigenvalues.pt')\n",
    "eigenvectors = torch.load('eigenvectors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_data(train_dataset[0][0],train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "PCA transform object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform=transform(eigenvalues,eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the PCA transform of the image. We can see the transform for each digit looks similar.   Try changing the variable <code>select_number</code> to change the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "#select_number from 0 -9\n",
    "select_number= 2\n",
    "for i,(X,y) in enumerate(train_dataset):\n",
    "    if y.item()==select_number:\n",
    "        j+=1\n",
    "        Xhat=transform.PCA(X)\n",
    "        show_data(torch.log(Xhat+1),y=y,raw_image=False)\n",
    "        plt.show()\n",
    "    if j==5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>References</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>K. K. Pal and K. S. Sudeep, “Preprocessing for image classification by convolutional neural networks,” in 2016 IEEE International Conference on Recent Trends in Electronics, Information Communication Technology (RTEICT), 2016, pp. 1778–1781.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
